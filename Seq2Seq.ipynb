{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMN3vJ6YH6luVxqsP6bOmh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Iv0GCK-MDO-",
        "outputId": "469eb3f3-e48f-468c-aac6-71a068ec974a"
      },
      "source": [
        "!python -m spacy download de\r\n",
        "!pip install torchtext==0.6.0\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "from torchtext.data.metrics import bleu_score\r\n",
        "import numpy as np\r\n",
        "import spacy\r\n",
        "import random\r\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (0.1.95)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR6o-r_TOGMn",
        "outputId": "c002f6bb-ef33-4326-bcfb-4de516d92f6f"
      },
      "source": [
        "!ls -a multi30k/\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\t\t\t   test2016.de\ttrain.de\t val.de\n",
            "..\t\t\t   test2016.en\ttrain.en\t val.en\n",
            "mmt_task1_test2016.tar.gz  test2016.fr\ttraining.tar.gz  validation.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66ceMgsvMRNd"
      },
      "source": [
        "nlp_de = spacy.load('de')\r\n",
        "nlp_eng = spacy.load('en')\r\n",
        "\r\n",
        "def tokenizer_de(text):\r\n",
        "    return [tok.text for tok in nlp_de.tokenizer(text)]\r\n",
        "\r\n",
        "\r\n",
        "def tokenizer_eng(text):\r\n",
        "    return [tok.text for tok in nlp_eng.tokenizer(text)]\r\n",
        "\r\n",
        "\r\n",
        "german = Field(tokenize = tokenizer_de, lower=True, init_token ='<sos>', eos_token = '<eos>')\r\n",
        "\r\n",
        "english = Field(tokenize = tokenizer_eng, lower=True, init_token ='<sos>', eos_token = '<eos>')\r\n",
        "\r\n",
        "train_data, validation_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (german, english))\r\n",
        "\r\n",
        "german.build_vocab(train_data, max_size = 10000, min_freq = 2) \r\n",
        "english.build_vocab(train_data, max_size = 10000, min_freq = 2) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "uedxAfxqNnKE",
        "outputId": "bb45612c-a604-43a0-99d4-387da130a7f9"
      },
      "source": [
        "x = next(iter(train_iterator))\r\n",
        "print(x.src)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-59a2fadcc60d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_iterator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_lypgEUL6gU"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\r\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # c_shape (seq_length, batch_size, )\r\n",
        "        embedding = self.dropout(self.embedding(x))\r\n",
        "        # embedding (seq_length, batch_size, embedding_size)\r\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\r\n",
        "\r\n",
        "        return hidden, cell\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\r\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\r\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\r\n",
        "\r\n",
        "    \r\n",
        "    def forward(self, x, hidden, cell):\r\n",
        "        \r\n",
        "        # shape of x (batch_size) but we want (1,batch_size) \r\n",
        "        x = x.unsqueeze(0)\r\n",
        "        embedding = self.dropout(self.embedding(x))\r\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\r\n",
        "        # shape of outputs (1, N, hidden_size)\r\n",
        "\r\n",
        "        predictions = self.fc(outputs)\r\n",
        "        # shape 1, N, length of vocab\r\n",
        "\r\n",
        "        predictions = predictions.squeeze(0)\r\n",
        "\r\n",
        "        return predictions, hidden, cell\r\n",
        "\r\n",
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder):\r\n",
        "        super(Seq2Seq, self).__init__()\r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, source, target, teacher_force_ratio = 0.5):\r\n",
        "        batch_size = source.shape[1]\r\n",
        "        target_len = target.shape[0]\r\n",
        "        target_vocab_size = len(english.vocab)\r\n",
        "\r\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\r\n",
        "\r\n",
        "        hidden, cell = self.encoder(source)\r\n",
        "        \r\n",
        "    \r\n",
        "        #grab start toker\r\n",
        "        x = target[0]\r\n",
        "\r\n",
        "        for t in range(1, target_len):\r\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\r\n",
        "\r\n",
        "            outputs[t] = output\r\n",
        "\r\n",
        "            # (N, english_vocab_size)\r\n",
        "            best_guess = output.argmax(1)\r\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\r\n",
        "\r\n",
        "\r\n",
        "        return outputs\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGn73VsfSs7c"
      },
      "source": [
        "### Training\r\n",
        "# training hyperparameters\r\n",
        "\r\n",
        "num_epochs = 100\r\n",
        "learning_rate = 0.0001\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Model hyperparameters\r\n",
        "load_model = False\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "input_size_encoder = len(german.vocab)\r\n",
        "input_size_decoder = len(english.vocab)\r\n",
        "output_size = len(english.vocab)\r\n",
        "encoder_embedding_size = 300\r\n",
        "decoder_embedding_size = 300\r\n",
        "hidden_size = 1024\r\n",
        "num_layers = 3\r\n",
        "enc_dropout = 0.5\r\n",
        "dec_dropout = 0.5\r\n",
        "\r\n",
        "#Tensor board\r\n",
        "writer = SummaryWriter()\r\n",
        "step = 0\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, validation_data, test_data),\r\n",
        "    batch_size = batch_size,\r\n",
        "    sort_within_batch = True,\r\n",
        "    sort_key = lambda x: len(x.src),\r\n",
        "    device = device\r\n",
        ")\r\n",
        "\r\n",
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\r\n",
        "\r\n",
        "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)\r\n",
        "\r\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\r\n",
        "\r\n",
        "pad_idx = english.vocab.stoi['<pad>']\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_pFtQfTZ6XK",
        "outputId": "fb4abe6b-a7c3-4b32-c492-43810ffc12e4"
      },
      "source": [
        "b = next(iter(train_iterator)).src\r\n",
        "print(b.size())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUqNG2TdVUNr",
        "outputId": "3279e66e-fd6c-418b-ad0a-661b35c21822"
      },
      "source": [
        "encoder_net(b)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 64, 2048])\n",
            "torch.Size([6, 64, 1024])\n",
            "torch.Size([6, 64, 1024])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFbUXIYcWrvp",
        "outputId": "1d7df54a-23ac-4241-f6e9-22533dbecb87"
      },
      "source": [
        "encoder_net(next(iter(train_iterator)).src)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 64, 2048])\n",
            "torch.Size([6, 64, 1024])\n",
            "torch.Size([6, 64, 1024])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FVSNXoHOtwI"
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\r\n",
        "    # Load german tokenizer\r\n",
        "    spacy_ger = spacy.load(\"de\")\r\n",
        "\r\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\r\n",
        "    if type(sentence) == str:\r\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    # print(tokens)\r\n",
        "\r\n",
        "    # sys.exit()\r\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\r\n",
        "    tokens.insert(0, german.init_token)\r\n",
        "    tokens.append(german.eos_token)\r\n",
        "\r\n",
        "    # Go through each german token and convert to an index\r\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    # Convert to Tensor\r\n",
        "    sentence_tensor = torch.tensor(text_to_indices).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    # Build encoder hidden, cell state\r\n",
        "    with torch.no_grad():\r\n",
        "        hidden, cell = model.encoder(sentence_tensor)\r\n",
        "\r\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\r\n",
        "\r\n",
        "    for _ in range(max_length):\r\n",
        "        previous_word = torch.tensor([outputs[-1]]).to(device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\r\n",
        "            best_guess = output.argmax(1).item()\r\n",
        "\r\n",
        "        outputs.append(best_guess)\r\n",
        "\r\n",
        "        # Model predicts it's the end of the sentence\r\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\r\n",
        "            break\r\n",
        "\r\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\r\n",
        "\r\n",
        "    # remove start token\r\n",
        "    return translated_sentence[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTjlKHCwSvxx",
        "outputId": "401d3f4a-98e1-4015-f2e6-7725c7da5e47"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "# saving stuff\r\n",
        "\r\n",
        "v_inp_data, v_tgt_data = next(iter(valid_iterator)).src,  next(iter(valid_iterator)).trg\r\n",
        "\r\n",
        "i = 0\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    print(f'Epoch {epoch} / {num_epochs}')\r\n",
        "\r\n",
        "    checkpoint = {'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\r\n",
        "\r\n",
        "    # save_checkpoint(checkpoint)\r\n",
        "    a = translate_sentence(model, 'Der Himmel ist heute klar. Die Sonne scheint.', german, english, device)\r\n",
        "    print(a)\r\n",
        "    for batch_idx, batch in enumerate(train_iterator):\r\n",
        "        inp_data = batch.src.to(device)\r\n",
        "        target = batch.trg.to(device)\r\n",
        "\r\n",
        "        output = model(inp_data, target)\r\n",
        "        #output shape (tgt_len ,b_size, output_dim)\r\n",
        "\r\n",
        "        if i == 0:\r\n",
        "            writer.add_graph(model.encoder, inp_data)\r\n",
        "            i += 1\r\n",
        "\r\n",
        "        output = output[1:].reshape(-1, output.shape[2])\r\n",
        "        target = target[1:].reshape(-1)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss = criterion(output, target)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        writer.add_scalar('/Training Loss/Tr_Loss', loss, global_step = step)\r\n",
        "\r\n",
        "        #val loss\r\n",
        "        v_output = model(v_inp_data, v_tgt_data)\r\n",
        "        #output shape (tgt_len ,b_size, output_dim)\r\n",
        "\r\n",
        "        v_output = v_output[1:].reshape(-1, v_output.shape[2])\r\n",
        "        v_target = v_tgt_data[1:].reshape(-1)\r\n",
        "\r\n",
        "        val_loss = criterion(v_output, v_target)\r\n",
        "        writer.add_scalar('/Validation Loss/Val_loss', val_loss, global_step = step)\r\n",
        "\r\n",
        "        step += 1\r\n",
        "\r\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 100\n",
            "['cow', 'port', 'formation', 'skim', 'skim', 'companion', 'companion', 'skim', 'skim', 'grilling', 'grilling', 'grilling', 'grilling', 'skiing', 'grilling', 'grilling', 'interviewed', 'grilling', 'grilling', 'grilling', 'grilling', 'aquarium', 'aquarium', 'aquarium', 'aquarium', 'aquarium', 'fedora', 'booths', 'slowly', 'skim', 'skim', 'skim', 'aquarium', 'skiing', 'skiing', 'cattle', 'grilling', 'tricks', 'entertainment', 'employees', 'aquarium', 'grinds', 'avoid', 'tricks', 'tricks', 'tricks', 'tricks', 'after', 'structure', 'after']\n",
            "Epoch 1 / 100\n",
            "['a', 'group', 'of', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch 2 / 100\n",
            "['the', 'dog', 'is', 'a', 'a', 'a', 'a', 'a', '.', '.', '<eos>']\n",
            "Epoch 3 / 100\n",
            "['the', 'is', 'is', 'a', 'the', 'the', 'of', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 4 / 100\n",
            "['the', 'person', 'is', 'is', 'the', 'the', '<unk>', 'is', '.', 'the', '.', '.', '<eos>']\n",
            "Epoch 5 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 6 / 100\n",
            "['the', 'person', 'is', 'is', 'the', 'the', 'the', '<unk>', '.', '.', '<eos>']\n",
            "Epoch 7 / 100\n",
            "['the', 'the', 'is', 'is', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 8 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', '<unk>', 'of', 'the', '.', '.', '<eos>']\n",
            "Epoch 9 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'of', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 10 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 11 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 12 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 13 / 100\n",
            "['the', '<unk>', '<unk>', 'the', '<unk>', 'is', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 14 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 15 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 16 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 17 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 18 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 19 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 20 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 21 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 22 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 23 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 24 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', '<unk>', 'the', '.', '.', '<eos>']\n",
            "Epoch 25 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 26 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'the', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 27 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 28 / 100\n",
            "['the', '<unk>', \"'s\", 'is', 'is', 'the', '<unk>', 'the', '.', '.', '<eos>']\n",
            "Epoch 29 / 100\n",
            "['the', '<unk>', 'player', 'is', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 30 / 100\n",
            "['the', 'the', \"'s\", 'car', 'is', 'is', 'the', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 31 / 100\n",
            "['the', 'new', 'player', 'was', 'is', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 32 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 33 / 100\n",
            "['the', '<unk>', 'player', 'was', 'is', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 34 / 100\n",
            "['the', '<unk>', 'is', 'is', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 35 / 100\n",
            "['the', '<unk>', 'is', 'is', 'was', 'in', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 36 / 100\n",
            "['the', 'new', '<unk>', 'was', 'is', 'is', 'is', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 37 / 100\n",
            "['the', '<unk>', 'is', '<unk>', 'the', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 38 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'is', '<unk>', 'at', 'the', '.', '.', '<eos>']\n",
            "Epoch 39 / 100\n",
            "['the', 'new', 'is', 'was', 'is', '<unk>', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 40 / 100\n",
            "['the', '<unk>', 'is', 'was', '<unk>', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 41 / 100\n",
            "['the', '<unk>', 'is', 'was', 'was', 'is', '<unk>', 'at', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 42 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 43 / 100\n",
            "['the', 'new', 'was', 'was', 'was', 'is', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 44 / 100\n",
            "['the', 'new', 'vendor', 'is', 'was', 'is', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 45 / 100\n",
            "['the', '<unk>', \"'s\", 'concert', 'was', 'is', '<unk>', 'at', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 46 / 100\n",
            "['the', '<unk>', '<unk>', 'was', 'is', 'is', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 47 / 100\n",
            "['the', '<unk>', 'is', 'was', 'is', 'the', 'the', '<unk>', '.', '.', '<eos>']\n",
            "Epoch 48 / 100\n",
            "['the', 'basketball', 'basketball', 'player', 'is', 'is', '<unk>', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 49 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 50 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', '<unk>', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 51 / 100\n",
            "['the', 'new', '<unk>', 'is', 'is', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 52 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 53 / 100\n",
            "['the', '<unk>', 'is', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 54 / 100\n",
            "['the', 'new', 'basketball', 'player', 'is', 'just', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 55 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'the', '<unk>', 'at', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 56 / 100\n",
            "['the', 'new', 'basketball', '<unk>', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 57 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'the', '<unk>', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 58 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', '<unk>', '.', '.', '<eos>']\n",
            "Epoch 59 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 60 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'by', 'the', '<unk>', 'stadium', '.', '<eos>']\n",
            "Epoch 61 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', '<unk>', 'the', 'the', 'of', 'the', '.', '<eos>']\n",
            "Epoch 62 / 100\n",
            "['the', '<unk>', 'is', '<unk>', 'is', 'at', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 63 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', '<unk>', 'is', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 64 / 100\n",
            "['the', '<unk>', 'is', 'is', 'to', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 65 / 100\n",
            "['the', '<unk>', \"'s\", 'concert', 'is', 'the', 'the', 'at', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 66 / 100\n",
            "['the', '<unk>', 'concert', 'is', '<unk>', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 67 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 68 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', 'at', 'the', '.', '<eos>']\n",
            "Epoch 69 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'the', 'the', 'line', '.', '<eos>']\n",
            "Epoch 70 / 100\n",
            "['the', '<unk>', 'is', 'was', 'to', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 71 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 72 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'the', 'the', 'at', 'the', '.', '<eos>']\n",
            "Epoch 73 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', 'the', 'basket', '.', '<eos>']\n",
            "Epoch 74 / 100\n",
            "['the', '<unk>', 'is', 'is', 'to', 'the', '<unk>', 'at', 'the', 'the', '.', '<eos>']\n",
            "Epoch 75 / 100\n",
            "['the', '<unk>', 'is', 'going', 'by', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 76 / 100\n",
            "['the', 'new', 'concert', 'is', 'just', 'for', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 77 / 100\n",
            "['the', '<unk>', 'is', '<unk>', '<unk>', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 78 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'the', 'the', 'middle', 'of', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 79 / 100\n",
            "['the', '<unk>', 'is', 'just', 'to', 'the', '<unk>', 'for', 'the', '.', '<eos>']\n",
            "Epoch 80 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 81 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'to', 'the', 'the', 'basket', '.', '<eos>']\n",
            "Epoch 82 / 100\n",
            "['the', 'new', '<unk>', 'is', 'to', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 83 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'to', 'the', 'basket', '.', '<eos>']\n",
            "Epoch 84 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'is', '<unk>', 'the', 'the', '.', '<eos>']\n",
            "Epoch 85 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'just', 'the', '<unk>', 'line', '.', '<eos>']\n",
            "Epoch 86 / 100\n",
            "['the', '<unk>', 'is', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', '.', '<eos>']\n",
            "Epoch 87 / 100\n",
            "['the', '<unk>', 'is', '<unk>', '<unk>', 'by', 'the', 'the', 'at', 'the', '.', '<eos>']\n",
            "Epoch 88 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'even', 'to', 'the', 'the', 'at', '.', '<eos>']\n",
            "Epoch 89 / 100\n",
            "['the', 'new', 'concert', 'is', '<unk>', 'at', 'the', 'the', 'sun', '.', '<eos>']\n",
            "Epoch 90 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', '<unk>', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 91 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', '<unk>', 'line', '.', '<eos>']\n",
            "Epoch 92 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 93 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'going', 'to', 'the', '<unk>', 'at', '.', '<eos>']\n",
            "Epoch 94 / 100\n",
            "['the', '<unk>', 'concert', 'is', 'dropping', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 95 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'to', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 96 / 100\n",
            "['the', '<unk>', \"'s\", '<unk>', 'is', 'even', 'to', 'the', 'the', '.', '<eos>']\n",
            "Epoch 97 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'even', 'by', 'the', 'middle', 'at', 'the', '.', '<eos>']\n",
            "Epoch 98 / 100\n",
            "['the', '<unk>', 'is', 'just', '<unk>', 'to', 'the', 'the', 'line', '.', '<eos>']\n",
            "Epoch 99 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', 'the', 'stadium', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yH0LSB9dufS"
      },
      "source": [
        "def bleu(data, model, german, english, device):\r\n",
        "    references = []\r\n",
        "    candidates = []\r\n",
        "    i = 0\r\n",
        "    for example in data:\r\n",
        "        print(i)\r\n",
        "        i += 1\r\n",
        "        src = example.src\r\n",
        "        trg = example.trg\r\n",
        "        prediction = translate_sentence(model, src, german, english, device)\r\n",
        "        prediction = prediction[:-1]  # remove <eos> token\r\n",
        "\r\n",
        "        references.append([trg])\r\n",
        "        candidates.append(prediction)\r\n",
        "\r\n",
        "    return bleu_score(candidates, references)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_BGN9HAYV2B"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DINHI9Q0QNHM"
      },
      "source": [
        "# Attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sESEvWaBMW9f"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\r\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional = True, dropout = p)\r\n",
        "        \r\n",
        "      \r\n",
        "    def forward(self, x):\r\n",
        "        # c_shape (seq_length, batch_size, )\r\n",
        "        embedding = self.dropout(self.embedding(x))\r\n",
        "        # embedding (seq_length, batch_size, embedding_size)\r\n",
        "        encoder_states, (hidden, cell) = self.rnn(embedding)\r\n",
        "\r\n",
        "        return encoder_states, hidden, cell\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Attention_Decoder(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\r\n",
        "        super(Attention_Decoder, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\r\n",
        "        self.rnn = nn.LSTM(embedding_size+2*hidden_size, hidden_size, num_layers, dropout=p)\r\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\r\n",
        "\r\n",
        "        self.energy = nn.Linear(embedding_size+4*hidden_size,1)\r\n",
        "        self.softmax = nn.Softmax(dim = 0)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "    \r\n",
        "    def forward(self, x, encoder_states, hidden, cell):\r\n",
        "        \r\n",
        "        # shape of x (batch_size) but we want (1,batch_size) \r\n",
        "        x = x.unsqueeze(0)\r\n",
        "        embedding = self.dropout(self.embedding(x))\r\n",
        "\r\n",
        "        # encoder_states (seq_len, N, 2*hidden)\r\n",
        "        # embedding (1, N, embedding_size)\r\n",
        "        # previous (2, N, hidden_size)\r\n",
        "\r\n",
        "        print(hidden[0:1].shape)\r\n",
        "        print(embedding.shape)\r\n",
        "        hidden_ = torch.cat((hidden[0:1],hidden[1:],embedding),dim = 2)\r\n",
        "\r\n",
        "        hidden_reshaped = hidden_.repeat(encoder_states.shape[0],1,1)\r\n",
        "\r\n",
        "        print(hidden_reshaped.shape)\r\n",
        "        weights = self.softmax(self.relu(self.energy(torch.cat((hidden_reshaped, encoder_states), dim = 2))))\r\n",
        "\r\n",
        "        # attention: (seq_length, N, 1), snk\r\n",
        "        # encoder_states: (seq_length, N, hidden_size*2), snl\r\n",
        "        # we want context_vector: (1, N, hidden_size*2), i.e knl\r\n",
        "\r\n",
        "        context = torch.einsum('snk,snl->knl', weights, encoder_states)\r\n",
        "\r\n",
        "        input = torch.cat((context,embedding), dim = 2)\r\n",
        "\r\n",
        "        outputs, (hidden, cell) = self.rnn(input, (hidden, cell))\r\n",
        "        # shape of outputs (1, N, hidden_size)\r\n",
        "\r\n",
        "        predictions = self.fc(outputs)\r\n",
        "        # shape 1, N, length of vocab\r\n",
        "\r\n",
        "        predictions = predictions.squeeze(0)\r\n",
        "\r\n",
        "        return predictions, hidden, cell\r\n",
        "\r\n",
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder):\r\n",
        "        super(Seq2Seq, self).__init__()\r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, source, target, teacher_force_ratio = 0.5):\r\n",
        "        batch_size = source.shape[1]\r\n",
        "        target_len = target.shape[0]\r\n",
        "        target_vocab_size = len(english.vocab)\r\n",
        "\r\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\r\n",
        "\r\n",
        "        encoder_states, hidden, cell = self.encoder(source)\r\n",
        "        \r\n",
        "    \r\n",
        "        #grab start toker\r\n",
        "        x = target[0]\r\n",
        "\r\n",
        "        for t in range(1, target_len):\r\n",
        "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\r\n",
        "\r\n",
        "            outputs[t] = output\r\n",
        "\r\n",
        "            # (N, english_vocab_size)\r\n",
        "            best_guess = output.argmax(1)\r\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\r\n",
        "\r\n",
        "\r\n",
        "        return outputs\r\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDmmAgRrAx2F",
        "outputId": "cd49ae03-9c75-4c9b-f9a4-9f2141c688b8"
      },
      "source": [
        "### Training\r\n",
        "# training hyperparameters\r\n",
        "\r\n",
        "num_epochs = 100\r\n",
        "learning_rate = 0.0001\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Model hyperparameters\r\n",
        "load_model = False\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "input_size_encoder = len(german.vocab)\r\n",
        "input_size_decoder = len(english.vocab)\r\n",
        "output_size = len(english.vocab)\r\n",
        "encoder_embedding_size = 300\r\n",
        "decoder_embedding_size = 300\r\n",
        "hidden_size = 1024\r\n",
        "num_layers = 1\r\n",
        "enc_dropout = 0.5\r\n",
        "dec_dropout = 0.5\r\n",
        "\r\n",
        "#Tensor board\r\n",
        "writer = SummaryWriter()\r\n",
        "step = 0\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, validation_data, test_data),\r\n",
        "    batch_size = batch_size,\r\n",
        "    sort_within_batch = True,\r\n",
        "    sort_key = lambda x: len(x.src),\r\n",
        "    device = device\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\r\n",
        "\r\n",
        "decoder_net = Attention_Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)\r\n",
        "\r\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\r\n",
        "\r\n",
        "pad_idx = english.vocab.stoi['<pad>']\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\r\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "jFk_xspdA7dI",
        "outputId": "f8004574-5fff-4de6-9609-66e81669d739"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "# saving stuff\r\n",
        "\r\n",
        "v_inp_data, v_tgt_data = next(iter(valid_iterator)).src,  next(iter(valid_iterator)).trg\r\n",
        "\r\n",
        "i = 0\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    print(f'Epoch {epoch} / {num_epochs}')\r\n",
        "\r\n",
        "    checkpoint = {'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\r\n",
        "\r\n",
        "    # save_checkpoint(checkpoint)\r\n",
        "    # a = translate_sentence(model, 'Der Himmel ist heute klar. Die Sonne scheint.', german, english, device)\r\n",
        "    # print(a)\r\n",
        "    for batch_idx, batch in enumerate(train_iterator):\r\n",
        "        inp_data = batch.src.to(device)\r\n",
        "        target = batch.trg.to(device)\r\n",
        "\r\n",
        "        output = model(inp_data, target)\r\n",
        "        #output shape (tgt_len ,b_size, output_dim)\r\n",
        "\r\n",
        "        if i == 0:\r\n",
        "            writer.add_graph(model.encoder, inp_data)\r\n",
        "            i += 1\r\n",
        "\r\n",
        "        output = output[1:].reshape(-1, output.shape[2])\r\n",
        "        target = target[1:].reshape(-1)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss = criterion(output, target)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        writer.add_scalar('/Training Loss/Tr_Loss', loss, global_step = step)\r\n",
        "\r\n",
        "        #val loss\r\n",
        "        v_output = model(v_inp_data, v_tgt_data)\r\n",
        "        #output shape (tgt_len ,b_size, output_dim)\r\n",
        "\r\n",
        "        v_output = v_output[1:].reshape(-1, v_output.shape[2])\r\n",
        "        v_target = v_tgt_data[1:].reshape(-1)\r\n",
        "\r\n",
        "        val_loss = criterion(v_output, v_target)\r\n",
        "        writer.add_scalar('/Validation Loss/Val_loss', val_loss, global_step = step)\r\n",
        "\r\n",
        "        step += 1\r\n",
        "\r\n",
        "writer.close()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 100\n",
            "torch.Size([1, 64, 1024])\n",
            "torch.Size([1, 64, 300])\n",
            "torch.Size([13, 64, 2348])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-8353134416eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#output shape (tgt_len ,b_size, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-22b2f63a0f7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source, target, teacher_force_ratio)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-22b2f63a0f7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_states, hidden, cell)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;31m# shape of outputs (1, N, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 534\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    535\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    536\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 64, 1024), got [2, 64, 1024]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Bs09EcCMFt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}