{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Iv0GCK-MDO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9b0f26-6029-4ce5-b075-98fb28de51d4"
      },
      "source": [
        "!python -m spacy download de\r\n",
        "!pip install torchtext==0.6.0\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "from torchtext.data.metrics import bleu_score\r\n",
        "import numpy as np\r\n",
        "import spacy\r\n",
        "import random\r\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.3.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=16329ebaaa42fe864e9b05f347df2f0b1a3dea0beffc3a21eca8b4af65f683e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zmmahwf6/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 16.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR6o-r_TOGMn",
        "outputId": "c002f6bb-ef33-4326-bcfb-4de516d92f6f"
      },
      "source": [
        "!ls -a multi30k/\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\t\t\t   test2016.de\ttrain.de\t val.de\n",
            "..\t\t\t   test2016.en\ttrain.en\t val.en\n",
            "mmt_task1_test2016.tar.gz  test2016.fr\ttraining.tar.gz  validation.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66ceMgsvMRNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4877846-77a3-4b54-b4c4-58211219bb17"
      },
      "source": [
        "nlp_de = spacy.load('de')\r\n",
        "nlp_eng = spacy.load('en')\r\n",
        "\r\n",
        "def tokenizer_de(text):\r\n",
        "    return [tok.text for tok in nlp_de.tokenizer(text)]\r\n",
        "\r\n",
        "\r\n",
        "def tokenizer_eng(text):\r\n",
        "    return [tok.text for tok in nlp_eng.tokenizer(text)]\r\n",
        "\r\n",
        "\r\n",
        "german = Field(tokenize = tokenizer_de, lower=True, init_token ='<sos>', eos_token = '<eos>')\r\n",
        "\r\n",
        "english = Field(tokenize = tokenizer_eng, lower=True, init_token ='<sos>', eos_token = '<eos>')\r\n",
        "\r\n",
        "train_data, validation_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (german, english))\r\n",
        "\r\n",
        "german.build_vocab(train_data, max_size = 10000, min_freq = 2) \r\n",
        "english.build_vocab(train_data, max_size = 10000, min_freq = 2) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 508kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 175kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 167kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uedxAfxqNnKE",
        "outputId": "cd44a65b-4357-46e9-f686-e8f9767f40dd"
      },
      "source": [
        "x = next(iter(train_iterator))\r\n",
        "print(x.src)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   2,    2,    2],\n",
            "        [ 105,   18,   18],\n",
            "        [  41,   30,   41],\n",
            "        [  52,    7,   53],\n",
            "        [  27,  486,   10],\n",
            "        [   6, 3534,  307],\n",
            "        [3487,   59,  127],\n",
            "        [  10,    6,  317],\n",
            "        [ 928,    0, 3093],\n",
            "        [  75,  292, 3542],\n",
            "        [   4,    4,    4],\n",
            "        [   3,    3,    3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_lypgEUL6gU"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\r\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # c_shape (seq_length, batch_size, )\r\n",
        "        embedding = self.dropout(self.embedding(x))\r\n",
        "        # embedding (seq_length, batch_size, embedding_size)\r\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\r\n",
        "\r\n",
        "        return hidden, cell\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.dropout = nn.Dropout(p)\r\n",
        "\r\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\r\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\r\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\r\n",
        "\r\n",
        "    \r\n",
        "    def forward(self, x, hidden, cell):\r\n",
        "        \r\n",
        "        # shape of x (batch_size) but we want (1,batch_size) \r\n",
        "        x = x.unsqueeze(0)\r\n",
        "        embedding = self.dropout(self.embedding(x))\r\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\r\n",
        "        # shape of outputs (1, N, hidden_size)\r\n",
        "\r\n",
        "        predictions = self.fc(outputs)\r\n",
        "        # shape 1, N, length of vocab\r\n",
        "\r\n",
        "        predictions = predictions.squeeze(0)\r\n",
        "\r\n",
        "        return predictions, hidden, cell\r\n",
        "\r\n",
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder):\r\n",
        "        super(Seq2Seq, self).__init__()\r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, source, target, teacher_force_ratio = 0.5):\r\n",
        "        batch_size = source.shape[1]\r\n",
        "        target_len = target.shape[0]\r\n",
        "        target_vocab_size = len(english.vocab)\r\n",
        "\r\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\r\n",
        "\r\n",
        "        hidden, cell = self.encoder(source)\r\n",
        "        \r\n",
        "    \r\n",
        "        #grab start toker\r\n",
        "        x = target[0]\r\n",
        "\r\n",
        "        for t in range(1, target_len):\r\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\r\n",
        "\r\n",
        "            outputs[t] = output\r\n",
        "\r\n",
        "            # (N, english_vocab_size)\r\n",
        "            best_guess = output.argmax(1)\r\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\r\n",
        "\r\n",
        "\r\n",
        "        return outputs\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGn73VsfSs7c"
      },
      "source": [
        "### Training\r\n",
        "# training hyperparameters\r\n",
        "\r\n",
        "num_epochs = 100\r\n",
        "learning_rate = 0.0001\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Model hyperparameters\r\n",
        "load_model = False\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "input_size_encoder = len(german.vocab)\r\n",
        "input_size_decoder = len(english.vocab)\r\n",
        "output_size = len(english.vocab)\r\n",
        "encoder_embedding_size = 300\r\n",
        "decoder_embedding_size = 300\r\n",
        "hidden_size = 1024\r\n",
        "num_layers = 3\r\n",
        "enc_dropout = 0.5\r\n",
        "dec_dropout = 0.5\r\n",
        "\r\n",
        "#Tensor board\r\n",
        "writer = SummaryWriter()\r\n",
        "step = 0\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, validation_data, test_data),\r\n",
        "    batch_size = batch_size,\r\n",
        "    sort_within_batch = True,\r\n",
        "    sort_key = lambda x: len(x.src),\r\n",
        "    device = device\r\n",
        ")\r\n",
        "\r\n",
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\r\n",
        "\r\n",
        "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)\r\n",
        "\r\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\r\n",
        "\r\n",
        "pad_idx = english.vocab.stoi['<pad>']\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FVSNXoHOtwI"
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\r\n",
        "    # Load german tokenizer\r\n",
        "    spacy_ger = spacy.load(\"de\")\r\n",
        "\r\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\r\n",
        "    if type(sentence) == str:\r\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    # print(tokens)\r\n",
        "\r\n",
        "    # sys.exit()\r\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\r\n",
        "    tokens.insert(0, german.init_token)\r\n",
        "    tokens.append(german.eos_token)\r\n",
        "\r\n",
        "    # Go through each german token and convert to an index\r\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    # Convert to Tensor\r\n",
        "    sentence_tensor = torch.tensor(text_to_indices).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    # Build encoder hidden, cell state\r\n",
        "    with torch.no_grad():\r\n",
        "        hidden, cell = model.encoder(sentence_tensor)\r\n",
        "\r\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\r\n",
        "\r\n",
        "    for _ in range(max_length):\r\n",
        "        previous_word = torch.tensor([outputs[-1]]).to(device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\r\n",
        "            best_guess = output.argmax(1).item()\r\n",
        "\r\n",
        "        outputs.append(best_guess)\r\n",
        "\r\n",
        "        # Model predicts it's the end of the sentence\r\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\r\n",
        "            break\r\n",
        "\r\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\r\n",
        "\r\n",
        "    # remove start token\r\n",
        "    return translated_sentence[1:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTjlKHCwSvxx",
        "outputId": "ede0309b-4187-4251-b0fc-b0b910831399"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "# saving stuff\r\n",
        "\r\n",
        "v_inp_data, v_tgt_data = next(iter(valid_iterator)).src,  next(iter(valid_iterator)).trg\r\n",
        "\r\n",
        "i = 0\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    print(f'Epoch {epoch} / {num_epochs}')\r\n",
        "\r\n",
        "    checkpoint = {'state_dict':model.state_dict(), 'optimizer':optimizer.state_dict()}\r\n",
        "\r\n",
        "    # save_checkpoint(checkpoint)\r\n",
        "    a = translate_sentence(model, 'Der Himmel ist heute klar. Die Sonne scheint.', german, english, device)\r\n",
        "    print(a)\r\n",
        "    for batch_idx, batch in enumerate(train_iterator):\r\n",
        "        inp_data = batch.src.to(device)\r\n",
        "        target = batch.trg.to(device)\r\n",
        "\r\n",
        "        output = model(inp_data, target)\r\n",
        "        #output shape (tgt_len ,b_size, output_dim)\r\n",
        "\r\n",
        "        if i == 0:\r\n",
        "            writer.add_graph(model.encoder, inp_data)\r\n",
        "            i += 1\r\n",
        "\r\n",
        "        output = output[1:].reshape(-1, output.shape[2])\r\n",
        "        target = target[1:].reshape(-1)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss = criterion(output, target)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        writer.add_scalar('/Training Loss/Tr_Loss', loss, global_step = step)\r\n",
        "\r\n",
        "        #val loss\r\n",
        "        v_output = model(v_inp_data, v_tgt_data)\r\n",
        "        #output shape (tgt_len ,b_size, output_dim)\r\n",
        "\r\n",
        "        v_output = v_output[1:].reshape(-1, v_output.shape[2])\r\n",
        "        v_target = v_tgt_data[1:].reshape(-1)\r\n",
        "\r\n",
        "        val_loss = criterion(v_output, v_target)\r\n",
        "        writer.add_scalar('/Validation Loss/Val_loss', val_loss, global_step = step)\r\n",
        "\r\n",
        "        step += 1\r\n",
        "\r\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 100\n",
            "['cow', 'port', 'formation', 'skim', 'skim', 'companion', 'companion', 'skim', 'skim', 'grilling', 'grilling', 'grilling', 'grilling', 'skiing', 'grilling', 'grilling', 'interviewed', 'grilling', 'grilling', 'grilling', 'grilling', 'aquarium', 'aquarium', 'aquarium', 'aquarium', 'aquarium', 'fedora', 'booths', 'slowly', 'skim', 'skim', 'skim', 'aquarium', 'skiing', 'skiing', 'cattle', 'grilling', 'tricks', 'entertainment', 'employees', 'aquarium', 'grinds', 'avoid', 'tricks', 'tricks', 'tricks', 'tricks', 'after', 'structure', 'after']\n",
            "Epoch 1 / 100\n",
            "['a', 'group', 'of', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch 2 / 100\n",
            "['the', 'dog', 'is', 'a', 'a', 'a', 'a', 'a', '.', '.', '<eos>']\n",
            "Epoch 3 / 100\n",
            "['the', 'is', 'is', 'a', 'the', 'the', 'of', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 4 / 100\n",
            "['the', 'person', 'is', 'is', 'the', 'the', '<unk>', 'is', '.', 'the', '.', '.', '<eos>']\n",
            "Epoch 5 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 6 / 100\n",
            "['the', 'person', 'is', 'is', 'the', 'the', 'the', '<unk>', '.', '.', '<eos>']\n",
            "Epoch 7 / 100\n",
            "['the', 'the', 'is', 'is', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 8 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', '<unk>', 'of', 'the', '.', '.', '<eos>']\n",
            "Epoch 9 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'of', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 10 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 11 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 12 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 13 / 100\n",
            "['the', '<unk>', '<unk>', 'the', '<unk>', 'is', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 14 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 15 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 16 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 17 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 18 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 19 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 20 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 21 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 22 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 23 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 24 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', '<unk>', 'the', '.', '.', '<eos>']\n",
            "Epoch 25 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 26 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'the', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 27 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 28 / 100\n",
            "['the', '<unk>', \"'s\", 'is', 'is', 'the', '<unk>', 'the', '.', '.', '<eos>']\n",
            "Epoch 29 / 100\n",
            "['the', '<unk>', 'player', 'is', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 30 / 100\n",
            "['the', 'the', \"'s\", 'car', 'is', 'is', 'the', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 31 / 100\n",
            "['the', 'new', 'player', 'was', 'is', 'the', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 32 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 33 / 100\n",
            "['the', '<unk>', 'player', 'was', 'is', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 34 / 100\n",
            "['the', '<unk>', 'is', 'is', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 35 / 100\n",
            "['the', '<unk>', 'is', 'is', 'was', 'in', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 36 / 100\n",
            "['the', 'new', '<unk>', 'was', 'is', 'is', 'is', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 37 / 100\n",
            "['the', '<unk>', 'is', '<unk>', 'the', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 38 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'is', '<unk>', 'at', 'the', '.', '.', '<eos>']\n",
            "Epoch 39 / 100\n",
            "['the', 'new', 'is', 'was', 'is', '<unk>', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 40 / 100\n",
            "['the', '<unk>', 'is', 'was', '<unk>', 'the', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 41 / 100\n",
            "['the', '<unk>', 'is', 'was', 'was', 'is', '<unk>', 'at', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 42 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 43 / 100\n",
            "['the', 'new', 'was', 'was', 'was', 'is', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 44 / 100\n",
            "['the', 'new', 'vendor', 'is', 'was', 'is', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 45 / 100\n",
            "['the', '<unk>', \"'s\", 'concert', 'was', 'is', '<unk>', 'at', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 46 / 100\n",
            "['the', '<unk>', '<unk>', 'was', 'is', 'is', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 47 / 100\n",
            "['the', '<unk>', 'is', 'was', 'is', 'the', 'the', '<unk>', '.', '.', '<eos>']\n",
            "Epoch 48 / 100\n",
            "['the', 'basketball', 'basketball', 'player', 'is', 'is', '<unk>', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 49 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 50 / 100\n",
            "['the', '<unk>', 'is', 'the', 'the', '<unk>', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 51 / 100\n",
            "['the', 'new', '<unk>', 'is', 'is', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 52 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 53 / 100\n",
            "['the', '<unk>', 'is', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 54 / 100\n",
            "['the', 'new', 'basketball', 'player', 'is', 'just', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 55 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'the', '<unk>', 'at', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 56 / 100\n",
            "['the', 'new', 'basketball', '<unk>', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 57 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'the', '<unk>', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 58 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', '<unk>', '.', '.', '<eos>']\n",
            "Epoch 59 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', 'the', 'the', '.', '.', '<eos>']\n",
            "Epoch 60 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'by', 'the', '<unk>', 'stadium', '.', '<eos>']\n",
            "Epoch 61 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', '<unk>', 'the', 'the', 'of', 'the', '.', '<eos>']\n",
            "Epoch 62 / 100\n",
            "['the', '<unk>', 'is', '<unk>', 'is', 'at', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 63 / 100\n",
            "['the', '<unk>', 'is', 'is', 'the', '<unk>', 'is', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 64 / 100\n",
            "['the', '<unk>', 'is', 'is', 'to', 'the', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch 65 / 100\n",
            "['the', '<unk>', \"'s\", 'concert', 'is', 'the', 'the', 'at', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 66 / 100\n",
            "['the', '<unk>', 'concert', 'is', '<unk>', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 67 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 68 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', 'at', 'the', '.', '<eos>']\n",
            "Epoch 69 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'the', 'the', 'line', '.', '<eos>']\n",
            "Epoch 70 / 100\n",
            "['the', '<unk>', 'is', 'was', 'to', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 71 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', '<unk>', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 72 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'the', 'the', 'at', 'the', '.', '<eos>']\n",
            "Epoch 73 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', 'the', 'basket', '.', '<eos>']\n",
            "Epoch 74 / 100\n",
            "['the', '<unk>', 'is', 'is', 'to', 'the', '<unk>', 'at', 'the', 'the', '.', '<eos>']\n",
            "Epoch 75 / 100\n",
            "['the', '<unk>', 'is', 'going', 'by', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 76 / 100\n",
            "['the', 'new', 'concert', 'is', 'just', 'for', 'the', '<unk>', 'at', 'the', '.', '<eos>']\n",
            "Epoch 77 / 100\n",
            "['the', '<unk>', 'is', '<unk>', '<unk>', 'the', 'the', 'the', '.', '<eos>']\n",
            "Epoch 78 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'the', 'the', 'middle', 'of', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 79 / 100\n",
            "['the', '<unk>', 'is', 'just', 'to', 'the', '<unk>', 'for', 'the', '.', '<eos>']\n",
            "Epoch 80 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 81 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', 'to', 'the', 'the', 'basket', '.', '<eos>']\n",
            "Epoch 82 / 100\n",
            "['the', 'new', '<unk>', 'is', 'to', '<unk>', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 83 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'to', 'the', 'basket', '.', '<eos>']\n",
            "Epoch 84 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'is', 'is', '<unk>', 'the', 'the', '.', '<eos>']\n",
            "Epoch 85 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'just', 'the', '<unk>', 'line', '.', '<eos>']\n",
            "Epoch 86 / 100\n",
            "['the', '<unk>', 'is', '<unk>', '<unk>', 'is', '<unk>', 'the', 'the', '.', '<eos>']\n",
            "Epoch 87 / 100\n",
            "['the', '<unk>', 'is', '<unk>', '<unk>', 'by', 'the', 'the', 'at', 'the', '.', '<eos>']\n",
            "Epoch 88 / 100\n",
            "['the', '<unk>', '<unk>', '<unk>', 'even', 'to', 'the', 'the', 'at', '.', '<eos>']\n",
            "Epoch 89 / 100\n",
            "['the', 'new', 'concert', 'is', '<unk>', 'at', 'the', 'the', 'sun', '.', '<eos>']\n",
            "Epoch 90 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'is', '<unk>', 'the', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 91 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', '<unk>', 'line', '.', '<eos>']\n",
            "Epoch 92 / 100\n",
            "['the', '<unk>', '<unk>', 'is', '<unk>', 'to', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 93 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'going', 'to', 'the', '<unk>', 'at', '.', '<eos>']\n",
            "Epoch 94 / 100\n",
            "['the', '<unk>', 'concert', 'is', 'dropping', 'the', 'the', '<unk>', '.', '<eos>']\n",
            "Epoch 95 / 100\n",
            "['the', '<unk>', 'is', 'is', '<unk>', 'to', 'the', 'stadium', '.', '<eos>']\n",
            "Epoch 96 / 100\n",
            "['the', '<unk>', \"'s\", '<unk>', 'is', 'even', 'to', 'the', 'the', '.', '<eos>']\n",
            "Epoch 97 / 100\n",
            "['the', '<unk>', '<unk>', 'is', 'even', 'by', 'the', 'middle', 'at', 'the', '.', '<eos>']\n",
            "Epoch 98 / 100\n",
            "['the', '<unk>', 'is', 'just', '<unk>', 'to', 'the', 'the', 'line', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yH0LSB9dufS"
      },
      "source": [
        "def bleu(data, model, german, english, device):\r\n",
        "    references = []\r\n",
        "    candidates = []\r\n",
        "    i = 0\r\n",
        "    for example in data:\r\n",
        "        print(i)\r\n",
        "        i += 1\r\n",
        "        src = example.src\r\n",
        "        trg = example.trg\r\n",
        "        prediction = translate_sentence(model, src, german, english, device)\r\n",
        "        prediction = prediction[:-1]  # remove <eos> token\r\n",
        "\r\n",
        "        references.append([trg])\r\n",
        "        candidates.append(prediction)\r\n",
        "\r\n",
        "    return bleu_score(candidates, references)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_BGN9HAYV2B"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sESEvWaBMW9f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}